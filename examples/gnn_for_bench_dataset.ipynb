{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Latency Dataset - GNN Model\r\n",
    "\r\n",
    "This example will demonstrate our ability to predict latency with data from NN-meter through GNN. We will first build our GNN model, which is constructed based on GraphSAGE, and maxpooling is selected as out pooling method. Next, we will start training after the data is loaded.\r\n",
    "\r\n",
    "Let's start our journey!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1: Build our GraphSAGE Model\r\n",
    "\r\n",
    "We built our model with the help of DGL library."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "from torch.nn.modules.module import Module\r\n",
    "\r\n",
    "from dgl.nn.pytorch.glob import MaxPooling\r\n",
    "import dgl.nn as dglnn\r\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\r\n",
    "\r\n",
    "\r\n",
    "class GNN(Module):\r\n",
    "    def __init__(self, \r\n",
    "                num_features=0, \r\n",
    "                num_layers=2,\r\n",
    "                num_hidden=32,\r\n",
    "                dropout_ratio=0):\r\n",
    "\r\n",
    "        super(GNN, self).__init__()\r\n",
    "        self.nfeat = num_features\r\n",
    "        self.nlayer = num_layers\r\n",
    "        self.nhid = num_hidden\r\n",
    "        self.dropout_ratio = dropout_ratio\r\n",
    "        self.gc = nn.ModuleList([dglnn.SAGEConv(self.nfeat if i==0 else self.nhid, self.nhid, 'pool') for i in range(self.nlayer)])\r\n",
    "        self.bn = nn.ModuleList([nn.LayerNorm(self.nhid) for i in range(self.nlayer)])\r\n",
    "        self.relu = nn.ModuleList([nn.ReLU() for i in range(self.nlayer)])\r\n",
    "        self.pooling = MaxPooling()\r\n",
    "        self.fc = nn.Linear(self.nhid, 1)\r\n",
    "        self.fc1 = nn.Linear(self.nhid, self.nhid)\r\n",
    "        self.dropout = nn.ModuleList([nn.Dropout(self.dropout_ratio) for i in range(self.nlayer)])\r\n",
    "\r\n",
    "    def forward_single_model(self, g, features):\r\n",
    "        x = self.relu[0](self.bn[0](self.gc[0](g, features)))\r\n",
    "        x = self.dropout[0](x)\r\n",
    "        for i in range(1,self.nlayer):\r\n",
    "            x = self.relu[i](self.bn[i](self.gc[i](g, x)))\r\n",
    "            x = self.dropout[i](x)\r\n",
    "        return x\r\n",
    "\r\n",
    "    def forward(self, g, features):\r\n",
    "        x = self.forward_single_model(g, features)\r\n",
    "        with g.local_scope():\r\n",
    "            g.ndata['h'] = x\r\n",
    "            x = self.pooling(g, x)\r\n",
    "            x = self.fc1(x)\r\n",
    "            return self.fc(x)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2: Loading Data.\r\n",
    "\r\n",
    "Next, we will finish loading the data and learn about the size of the Training and Testing datasets."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import os\r\n",
    "from nn_meter.dataset import gnn_dataloader\r\n",
    "\r\n",
    "__user_dataset_folder__ = os.path.expanduser('~/.nn_meter/dataset')\r\n",
    "print(\"Processing Training Set.\")\r\n",
    "train_set = gnn_dataloader.GNNDataset(__user_dataset_folder__, train=True, device='cpu') \r\n",
    "print(\"Processing Testing Set.\")\r\n",
    "test_set = gnn_dataloader.GNNDataset(__user_dataset_folder__, train=False, device='cpu')\r\n",
    "\r\n",
    "train_loader = gnn_dataloader.GNNDataloader(train_set, batchsize=1 , shuffle=True)\r\n",
    "test_loader = gnn_dataloader.GNNDataloader(test_set, batchsize=1, shuffle=False)\r\n",
    "print('Train Dataset Size:', len(train_set))\r\n",
    "print('Testing Dataset Size:', len(test_set))\r\n",
    "print('Attribute tensor shape:', next(train_loader)[1].ndata['h'].size(1))\r\n",
    "ATTR_COUNT = next(train_loader)[1].ndata['h'].size(1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processing Training Set.\n",
      "Processing Testing Set.\n",
      "Train Dataset Size: 20732\n",
      "Testing Dataset Size: 5173\n",
      "Attribute tensor shape: 26\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3: Run and Test\r\n",
    "\r\n",
    "We can run the model and evaluate it now!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "if torch.cuda.is_available():\r\n",
    "    print(\"Using CUDA.\")\r\n",
    "# device = \"cpu\"\r\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "\r\n",
    "load_model = False\r\n",
    "if load_model:\r\n",
    "    model = GNN(ATTR_COUNT, 3, 400, 0.1).to(device)\r\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=4e-4)\r\n",
    "    checkpoint = torch.load('LatencyGNN.pt')\r\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\r\n",
    "    opt.load_state_dict(checkpoint['optimizer_state_dict'])\r\n",
    "    # EPOCHS = checkpoint['epoch']\r\n",
    "    EPOCHS = 0\r\n",
    "    loss_func = checkpoint['loss']\r\n",
    "else:\r\n",
    "    model = GNN(ATTR_COUNT, 3, 400, 0.1).to(device)\r\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=4e-4)\r\n",
    "    EPOCHS=20\r\n",
    "    loss_func = nn.L1Loss()\r\n",
    "\r\n",
    "lr_scheduler = CosineAnnealingLR(opt, T_max=EPOCHS)\r\n",
    "loss_sum = 0\r\n",
    "for epoch in range(EPOCHS):\r\n",
    "    train_length = len(train_set)\r\n",
    "    tran_acc_ten = 0\r\n",
    "    loss_sum = 0 \r\n",
    "    # latency, graph, types, flops\r\n",
    "    for batched_l, batched_g in train_loader:\r\n",
    "        opt.zero_grad()\r\n",
    "        batched_l = batched_l.to(device).float()\r\n",
    "        batched_g = batched_g.to(device)\r\n",
    "        batched_f = batched_g.ndata['h'].float()\r\n",
    "        logits = model(batched_g, batched_f)\r\n",
    "        for i in range(len(batched_l)):\r\n",
    "            pred_latency = logits[i].item()\r\n",
    "            prec_latency = batched_l[i].item()\r\n",
    "            if (pred_latency >= 0.9 * prec_latency) and (pred_latency <= 1.1 * prec_latency):\r\n",
    "                tran_acc_ten += 1\r\n",
    "        # print(\"true latency: \", batched_l)\r\n",
    "        # print(\"Predict latency: \", logits)\r\n",
    "        batched_l = torch.reshape(batched_l, (-1 ,1))\r\n",
    "        loss = loss_func(logits, batched_l)\r\n",
    "        loss_sum += loss\r\n",
    "        loss.backward()\r\n",
    "        opt.step()\r\n",
    "    lr_scheduler.step()\r\n",
    "    print(\"[Epoch \", epoch, \"]: \", \"Training accuracy within 10%: \", tran_acc_ten / train_length * 100, \" %.\")\r\n",
    "    # print('Learning Rate:', lr_scheduler.get_last_lr())\r\n",
    "    # print('Loss:', loss_sum / train_length)\r\n",
    "\r\n",
    "torch.save({\r\n",
    "    'epoch': EPOCHS,\r\n",
    "    'model_state_dict': model.state_dict(),\r\n",
    "    'optimizer_state_dict': opt.state_dict(),\r\n",
    "    'loss': loss_func,\r\n",
    "}, 'LatencyGNN.pt')\r\n",
    "\r\n",
    "\r\n",
    "count = 0\r\n",
    "with torch.no_grad():\r\n",
    "    test_length = len(test_set)\r\n",
    "    test_acc_ten = 0\r\n",
    "    for batched_l, batched_g in test_loader:\r\n",
    "        batched_l = batched_l.to(device).float()\r\n",
    "        batched_g = batched_g.to(device)\r\n",
    "        batched_f = batched_g.ndata['h'].float()\r\n",
    "        result = model(batched_g, batched_f)\r\n",
    "        if (result.item() >= 0.9 * batched_l.item()) and (result.item() <= 1.1 * batched_l.item()):\r\n",
    "            test_acc_ten += 1\r\n",
    "        acc = (abs(result.item() - batched_l.item()) / batched_l.item()) * 100\r\n",
    "        count += 1\r\n",
    "    print(\"Testing accuracy within 10%: \", test_acc_ten / test_length * 100, \" %.\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Epoch  0 ]:  Training accuracy within 10%:  21.999807061547365  %.\n",
      "[Epoch  1 ]:  Training accuracy within 10%:  27.725255643449742  %.\n",
      "[Epoch  2 ]:  Training accuracy within 10%:  30.228632066370825  %.\n",
      "[Epoch  3 ]:  Training accuracy within 10%:  31.357322014277443  %.\n",
      "[Epoch  4 ]:  Training accuracy within 10%:  33.06000385876906  %.\n",
      "[Epoch  5 ]:  Training accuracy within 10%:  34.917036465367545  %.\n",
      "[Epoch  6 ]:  Training accuracy within 10%:  36.48466139301563  %.\n",
      "[Epoch  7 ]:  Training accuracy within 10%:  39.070036658306  %.\n",
      "[Epoch  8 ]:  Training accuracy within 10%:  40.10708084121165  %.\n",
      "[Epoch  9 ]:  Training accuracy within 10%:  41.530001929384525  %.\n",
      "[Epoch  10 ]:  Training accuracy within 10%:  43.26162454177118  %.\n",
      "[Epoch  11 ]:  Training accuracy within 10%:  45.34053636889832  %.\n",
      "[Epoch  12 ]:  Training accuracy within 10%:  48.45166891761528  %.\n",
      "[Epoch  13 ]:  Training accuracy within 10%:  50.945398417904684  %.\n",
      "[Epoch  14 ]:  Training accuracy within 10%:  54.5774647887324  %.\n",
      "[Epoch  15 ]:  Training accuracy within 10%:  56.08238471927455  %.\n",
      "[Epoch  16 ]:  Training accuracy within 10%:  59.54562994404785  %.\n",
      "[Epoch  17 ]:  Training accuracy within 10%:  62.41076596565696  %.\n",
      "[Epoch  18 ]:  Training accuracy within 10%:  63.65521898514373  %.\n",
      "[Epoch  19 ]:  Training accuracy within 10%:  64.6826162454177  %.\n",
      "Testing accuracy within 10%:  60.042528513435144  %.\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "0238da245144306487e61782d9cba9bf2e5e19842e5054371ac0cfbea9be2b57"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}